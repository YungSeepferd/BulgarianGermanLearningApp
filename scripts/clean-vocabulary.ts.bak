import { readFile, writeFile } from 'node:fs/promises';
import { VocabularyItemSchema } from '../src/lib/schemas/vocabulary.js';
import { ProcessingVocabularyItem, VocabularyCleaningRule, VocabularyCleaningReport } from './types/vocabulary-types';

/**
 * Vocabulary data cleaning pipeline
 * with comprehensive data normalization
 */
class VocabularyCleaner {
  private cleaningRules: VocabularyCleaningRule[] = [
    {
      name: 'Standardize Categories',
      test: (item: ProcessingVocabularyItem) => item.categories && Array.isArray(item.categories),
      fix: (item: ProcessingVocabularyItem) => ({
        ...item,
        categories: item.categories ? item.categories.map((category: string) =>
          category.toLowerCase().trim().replace(/\s+/g, '_')
        ) : ['uncategorized']
      })
    },
    {
      name: 'Normalize Difficulty',
      test: (item: ProcessingVocabularyItem) => typeof item.difficulty === 'number',
      fix: (item: ProcessingVocabularyItem) => ({
        ...item,
        difficulty: Math.min(5, Math.max(1, Math.round(item.difficulty)))
      })
    },
    {
      name: 'Initialize Metadata',
      test: (item: ProcessingVocabularyItem) => item.metadata !== undefined,
      fix: (item: ProcessingVocabularyItem) => ({
        ...item,
        metadata: item.metadata || {}
      })
    },
    {
      name: 'Clean Metadata',
      test: (item: ProcessingVocabularyItem) => item.metadata,
      fix: (item: ProcessingVocabularyItem) => {
        const metadata = item.metadata || {};
        const examples = metadata.examples && Array.isArray(metadata.examples)
          ? metadata.examples.map((example: any) => ({
              ...example,
              german: example.german?.trim(),
              bulgarian: example.bulgarian?.trim(),
              context: example.context?.trim() || 'general'
            }))
          : metadata.examples || [];

        return {
          ...item,
          metadata: {
            ...metadata,
            examples,
            notes: metadata.notes?.trim()
          }
        };
      }
    },
    {
      name: 'Add Timestamps',
      test: (item: ProcessingVocabularyItem) => item.createdAt !== undefined && item.updatedAt !== undefined,
      fix: (item: ProcessingVocabularyItem) => {
        // Convert ISO strings to Date objects
        const createdAt = typeof item.createdAt === 'string'
          ? new Date(item.createdAt)
          : item.createdAt || new Date();
        const updatedAt = new Date();

        return {
          ...item,
          createdAt,
          updatedAt
        };
      }
    },
    {
      name: 'Initialize Boolean Fields',
      test: (item: ProcessingVocabularyItem) => item.isCommon !== undefined && item.isVerified !== undefined,
      fix: (item: ProcessingVocabularyItem) => ({
        ...item,
        isCommon: item.isCommon !== undefined ? Boolean(item.isCommon) : false,
        isVerified: item.isVerified !== undefined ? Boolean(item.isVerified) : false
      })
    },
    {
      name: 'Standardize Boolean Fields',
      test: (item: ProcessingVocabularyItem) => typeof item.isCommon === 'boolean' && typeof item.isVerified === 'boolean',
      fix: (item: ProcessingVocabularyItem) => ({
        ...item,
        isCommon: Boolean(item.isCommon),
        isVerified: Boolean(item.isVerified)
      })
    },
    {
      name: 'Initialize partOfSpeech',
      test: (item: ProcessingVocabularyItem) => item.partOfSpeech !== undefined,
      fix: (item: ProcessingVocabularyItem) => ({
        ...item,
        partOfSpeech: item.partOfSpeech || 'noun'
      })
    },
    {
      name: 'Normalize partOfSpeech',
      test: (item: ProcessingVocabularyItem) => item.partOfSpeech && typeof item.partOfSpeech === 'string',
      fix: (item: ProcessingVocabularyItem) => ({
        ...item,
        partOfSpeech: item.partOfSpeech.toLowerCase().trim()
      })
    }
  ];

  async clean(filePath: string): Promise<void> {
    const data = JSON.parse(await readFile(filePath, 'utf-8')) as { items: ProcessingVocabularyItem[] };
    const originalCount = data.items.length;

    // Apply cleaning rules
    const cleanedItems = data.items.map((item: ProcessingVocabularyItem) => {
      // Create a safe copy with proper initialization
      let cleanedItem: ProcessingVocabularyItem = {
        id: 'temp-' + Math.random().toString(36).substring(2, 9),
        german: 'unknown',
        bulgarian: 'unknown',
        partOfSpeech: 'noun',
        difficulty: 1,
        categories: ['uncategorized'],
        metadata: {},
        createdAt: new Date().toISOString(),
        updatedAt: new Date().toISOString(),
        isCommon: false,
        isVerified: false,
        ...item
      };

      this.cleaningRules.forEach(rule => {
        try {
          if (!rule.test(cleanedItem)) {
            cleanedItem = rule.fix(cleanedItem);
          }
        } catch (ruleError) {
          console.warn(`‚ö†Ô∏è Rule "${rule.name}" failed:`, ruleError instanceof Error ? ruleError.message : ruleError);
        }
      });
      return cleanedItem;
    });

    // Validate against schema
    const validationResult = await this.validateAgainstSchema(cleanedItems);
    if (!validationResult.valid) {
      console.error('‚ùå Schema validation failed after cleaning');
      console.error(validationResult.errors);
      throw new Error('Schema validation failed');
    }

    // Update data
    const cleanedData = {
      ...data,
      items: cleanedItems,
      metadata: {
        ...data.metadata,
        cleaning: {
          timestamp: new Date().toISOString(),
          originalCount,
          cleanedCount: cleanedItems.length,
          rulesApplied: this.cleaningRules.map(rule => rule.name)
        }
      }
    };

    // Save results
    await writeFile(filePath, JSON.stringify(cleanedData, null, 2));
    await writeFile(
      'data/vocabulary-cleaning-report.json',
      JSON.stringify({
        timestamp: new Date().toISOString(),
        summary: {
          originalCount,
          cleanedCount: cleanedItems.length,
          validationPassed: validationResult.valid
        },
        schemaValidation: validationResult,
        rulesApplied: this.cleaningRules.map(rule => rule.name)
      } as VocabularyCleaningReport, null, 2)
    );

    console.log(`‚úÖ Cleaning complete`);
    console.log(`üìä Items processed: ${originalCount}`);
    console.log(`üìã Report saved to data/vocabulary-cleaning-report.json`);
  }

  private async validateAgainstSchema(items: ProcessingVocabularyItem[]) {
    // Dynamic import to avoid circular dependencies
    try {
      const result: VocabularyProcessingResult = {
        valid: true,
        errors: []
      };

      for (const item of items) {
        try {
          const validation = VocabularyItemSchema.safeParse(item);
          if (!validation.success) {
            result.valid = false;
            result.errors.push({
              id: item.id || 'unknown',
              errors: validation.error.errors.map((e) =>
                `${e.path.join('.')}: ${e.message}`
              ).join(', '),
              details: validation.error.flatten()
            });
          }
        } catch (itemError) {
          result.valid = false;
          result.errors.push({
            id: item.id || 'unknown',
            errors: `Item validation failed: ${itemError instanceof Error ? itemError.message : String(itemError)}`
          });
        }
      }

      return result;
    } catch (importError) {
      console.error('‚ùå Failed to import vocabulary schema:', importError);
      throw new Error(`Schema import failed: ${importError instanceof Error ? importError.message : String(importError)}`);
    }
  }
}

// CLI Usage
const cleaner = new VocabularyCleaner();
cleaner.clean(process.argv[2] as string)
  .catch((error: unknown) => {
    console.error('‚ùå Cleaning failed:', error instanceof Error ? error.message : String(error));
    process.exit(1);
  });